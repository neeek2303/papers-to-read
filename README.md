Main articles I read or plan to read, as well as useful links.

# Articles


![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  - read
![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) - glance
![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+) - plan to read


## 3D pose estimation

https://paperswithcode.com/task/3d-human-pose-estimation -  comparison

https://github.com/trumDog/3d-human-pose-estimation - more information and articles

### Video


1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  3D human pose estimation in video with temporal convolutions and semi-supervised training (cvpr2019)

   [[paper](https://arxiv.org/abs/1811.11742)][[code](https://github.com/facebookresearch/VideoPose3D)]
   [[project](https://dariopavllo.github.io/VideoPose3D)]
   

2. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  3D Human Pose Estimation using Spatio-Temporal Networks with Explicit Occlusion Training (aaai2020)

    [[paper](http://tanrobby.github.io/focus_human.html)]
    [[project](http://tanrobby.github.io/focus_human.html)]



3. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) GAST-Net: Graph Attention Spatio-temporal Convolutional Networks for 3D Human Pose Estimation in Video (arXiv2020)

     [[paper](https://arxiv.org/abs/2003.14179)]
     [[code](https://github.com/fabro66/GAST-Net-3DPoseEstimation)]
     [[project](http://www.juanrojas.net/gast/)]
     
     
     
4. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) Motion Guided 3D Pose Estimation from Videos (eccv2020)

    [[paper](https://arxiv.org/abs/2004.13985)]
    



### Multi-view Methods


1. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) Learning Monocular 3D Human Pose Estimation from Multi-view Images (CVPR2018)

   [[paper](https://arxiv.org/abs/1803.04775)][code][project]
   
   
   
### 3D Pose Datasets

#### [Human3.6M](http://vision.imar.ro/human3.6m/description.php)
   
   [[downloader1](https://github.com/anibali/h36m-fetch)][[downloader2](https://github.com/kotaro-inoue/human3.6m_downloader)]
   
#### [HumanEva](http://humaneva.is.tue.mpg.de/datasets_human_1)

#### [MPI-INF-3DHP](http://gvv.mpi-inf.mpg.de/3dhp-dataset/)


## 2D pose tracking

https://paperswithcode.com/sota/pose-tracking-on-posetrack2017 - comparison
https://posetrack.net/leaderboard.php -  main liderboard 



1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  15 Keypoints Is All You Need (cvpr 2020)

   [[paper](https://arxiv.org/pdf/1912.02323.pdf)]
   [code]

2. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking

   [[paper](https://arxiv.org/pdf/1905.02822.pdf)]
   [[code](https://github.com/Guanghan/lighttrack)]
   
3. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Pose Flow: Efficient Online Pose Tracking

   [[paper](https://arxiv.org/pdf/1802.00977.pdf)]
   [[code](https://github.com/YuliangXiu/PoseFlow)]   
   
4. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Efficient Online Multi-Person 2D Pose Tracking with (cvpr 2019)
Recurrent Spatio-Temporal Affinity Fields

   [[paper](https://arxiv.org/pdf/1811.11975.pdf)]
   [code]  
   
5. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Simple Baselines for Human Pose Estimation and Tracking

   [[paper](https://arxiv.org/pdf/1804.06208.pdf)]
   [[code](https://github.com/microsoft/human-pose-estimation.pytorch)]
   
   
6. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Combining detection and tracking for human pose estimation in videos

   [[paper](https://arxiv.org/pdf/2003.13743.pdf )]
   [code]
  
7. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  BlazePose: On-device Real-time Body Pose tracking (google 2020)

   [[paper](https://arxiv.org/pdf/2006.10204.pdf)]
   [[code](https://github.com/google/mediapipe)]
   
#### [MOTA methric]( https://cvhci.anthropomatik.kit.edu/~stiefel/papers/ECCV2006WorkshopCameraReady.pdf)
   
   
## Image to Image translation

1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Unpaired Image-to-Image Translation
using Cycle-Consistent Adversarial Networks (CycleGAN) (cvpr 2020)

   [[paper](https://arxiv.org/pdf/1703.10593.pdf)] 
   [[code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix )]

2. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Unsupervised Image-to-Image Translation Networks (UNIT)

   [[paper](https://arxiv.org/pdf/1703.00848.pdf)]
   [[code](https://github.com/mingyuliutw/unit )]
   
3. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Multimodal Unsupervised Image-to-Image Translation (MUNIT)

   [[paper](https://arxiv.org/pdf/1804.04732.pdf )]
   [[code]( https://github.com/NVlabs/MUNIT )]   
   
4. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Unsupervised Attention-guided Image-to-Image Translation

   [[paper]( https://arxiv.org/pdf/1806.02311.pdf)]
   [[code](https://github.com/AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation)]  
   
5. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  U-GAT-IT: UNSUPERVISED GENERATIVE ATTENTIONAL NETWORKS WITH ADAPTIVE LAYERINSTANCE NORMALIZATION FOR IMAGE TO-IMAGE TRANSLATION

   [[paper](https://arxiv.org/pdf/1907.10830.pdf)]
   [[code](https://github.com/taki0112/UGATIT)]

6. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Reusing Discriminators for Encoding: Towards Unsupervised Image-to-Image Translation

   [[paper](https://arxiv.org/pdf/2003.00273.pdf)]
   [[code](https://github.com/alpc91/NICE-GAN-pytorch)]  
   
   
## Depth Super Resolution
https://github.com/TheDetial/Super-Resolution - more articles 

1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  High-Quality 3D Reconstruction With Depth Super-Resolution and Completion

   [[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8628990)]
   [code]

2. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) Channel Attention based Iterative Residual Learning for Depth Map Super-Resolution

   [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Song_Channel_Attention_Based_Iterative_Residual_Learning_for_Depth_Map_Super-Resolution_CVPR_2020_paper.pdf)]
   [code]
   
3. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) Simultaneously Color-Depth Super-Resolution with Conditional Generative Adversarial Network   

   [[paper](https://arxiv.org/pdf/1708.09105.pdf)]
   [code]
 
 
4. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) Multi-Scale Progressive Fusion Learning for Depth Map Super-Resolution

   [[paper](https://arxiv.org/pdf/2011.11865.pdf)]
   [code] 
   
5. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) Feedback Network for Image Super-Resolution  
   [[paper](https://arxiv.org/pdf/1903.09814.pdf)]
   [code] 
   
#### [RGBD datasets](http://www.michaelfirman.co.uk/RGBDdatasets/) 
   

## Depth Enhancement 

1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) Deep Depth Completion of a Single RGB-D Image

   [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Depth_Completion_CVPR_2018_paper.pdf )]
   [code]
   
2. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) Learning Guided Convolutional Network for Depth Completion 

   [[paper](https://arxiv.org/pdf/1708.09105.pdf)]
   [code]   
   
  

   
   
## Image Super Resolution

1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+) To learn image super-resolution, use a GAN to learn how to do image degradation first
   [[paper](https://arxiv.org/pdf/1807.11458.pdf)]
   [code]  

## Others

1. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  YOLACT++ Better Real-time Instance Segmentation 

   [[paper](https://arxiv.org/pdf/1912.06218.pdf)]
   [[code](https://github.com/dbolya/yolact)]


2. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  Deep High-Resolution Representation Learning for Human Pose Estimation 

   [[paper](https://arxiv.org/pdf/1902.09212v1.pdf)]
   [[code](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)]
   
3. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+)  Deep Surface Normal Estimation with Hierarchical RGB-D Fusion

   [[paper](http://wenxiusun.com/wordpress/wp-content/uploads/2019/10/Zeng_Deep_Surface_Normal_Estimation_With_Hierarchical_RGB-D_Fusion_CVPR_2019_paper.pdf)]
   [code]
   
4. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+)  Deep Image Prior

   [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.pdf)]
   [[code](https://github.com/DmitryUlyanov/deep-image-prior)]

5. ![#37ea0f](https://via.placeholder.com/15/37ea0f/000000?text=+)  An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale

   [[paper](https://arxiv.org/abs/2010.11929)]
   [[code](https://github.com/google-research/vision_transformer)]
   
6. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) Taming Transformers for High-Resolution Image Synthesis

   [[paper]](https://arxiv.org/pdf/2012.09841.pdf)
   [[code]]()
   
6. ![#e1ac06](https://via.placeholder.com/15/e1ac06/000000?text=+) Densely Connected Convolutional Networks

   [[paper]](https://arxiv.org/pdf/1608.06993.pdf)
   [[code]]()


# Usefull links


## Knowledge 
1. [Transformers understanding](http://jalammar.github.io/illustrated-transformer/) and [with code](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
2. [How GPT3 Works - Visualizations and Animations](http://jalammar.github.io/how-gpt3-works-visualizations-animations/), [The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/)
3. [Transformers pythorch](https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec#3fa3)
4. [GAN series](https://medium.com/@jonathan_hui/gan-gan-series-2d279f906e7b)
5. [Object detection](https://lilianweng.github.io/lil-log/2017/10/29/object-recognition-for-dummies-part-1.html)
6. [Only Numpy: Implementing Convolutional Neural Network using Numpy](https://becominghuman.ai/only-numpy-implementing-convolutional-neural-network-using-numpy-deriving-forward-feed-and-back-458a5250d6e4)
7. [Быстрая свертка по методу Шмуэля Винограда](https://m.habr.com/ru/post/477718/)
8. [Вычислительная фотография](https://vas3k.ru/blog/computational_photography/)
9. [Лекции NLA](https://docs.google.com/document/d/1nyzgdOuHI84oGLY2po1_Njq5qnamJByqNMXBfFHBoo0/edit)
10. [ML, DL and other lectures](https://deep-learning-drizzle.github.io/)
11. [Understanding the backward pass through Batch Normalization Layer](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html)
12. [Collection of the best ML resources by topic](https://madewithml.com/topics/?fbclid=IwAR0VSQDUySd9saxuoS486M58z7LmDaP5S8cGao6HO4RV5Obw9Mnyo_z_RI8)
13. [The Entire Computer Science Curriculum in 1000 YouTube Videos](https://laconicml.com/computer-science-curriculum-youtube-videos/)
14. [GCN understanding](https://www.topbots.com/graph-convolutional-networks/)
   
## Technical

1. [How to prevent Google Colab from disconnecting](https://medium.com/@shivamrawat_756/how-to-prevent-google-colab-from-disconnecting-717b88a128c0)
2. [Python graph gallery](https://python-graph-gallery.com/)
3. [Nice board for roadmap](https://miro.com/)
   
